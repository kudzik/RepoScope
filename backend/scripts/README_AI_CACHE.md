# AI Response Cache for Testing

System cache'owania odpowiedzi AI do redukcji koszt√≥w podczas test√≥w.

## üéØ Cel

- **Redukcja koszt√≥w**: Unikaj ponownych wywo≈Ça≈Ñ API AI podczas test√≥w
- **Szybsze testy**: U≈ºywaj zapisanych odpowiedzi zamiast czekaƒá na API
- **Przewidywalno≈õƒá**: Identyczne odpowiedzi dla tych samych prompt√≥w

## üöÄ Szybki start

### 1. W≈ÇƒÖcz tryb testowy

```bash
# Ustaw zmienne ≈õrodowiskowe
export TEST_MODE=true
export AI_CACHE_FILE=test_ai_responses_cache.json
export COLLECT_REAL_RESPONSES=true
```

### 2. Zbierz odpowiedzi AI

```bash
# Uruchom analizƒô na testowych repozytoriach
python backend/scripts/manage_ai_cache.py collect
```

### 3. Eksportuj cache

```bash
# Eksportuj do pliku testowego
python backend/scripts/manage_ai_cache.py export --output test_responses.json
```

### 4. U≈ºyj w testach

```bash
# Importuj cache w testach
python backend/scripts/manage_ai_cache.py import --file test_responses.json
```

## üìã Dostƒôpne komendy

### `collect` - Zbierz odpowiedzi AI

```bash
python backend/scripts/manage_ai_cache.py collect
```

- Uruchamia analizƒô na testowych repozytoriach
- Zbiera prawdziwe odpowiedzi AI
- Zapisuje do cache'u lokalnego

### `export` - Eksportuj cache

```bash
python backend/scripts/manage_ai_cache.py export --output my_cache.json
```

- Eksportuje cache do pliku JSON
- Usuwa metadane (timestampy)
- Przygotowuje do u≈ºycia w testach

### `import` - Importuj cache

```bash
python backend/scripts/manage_ai_cache.py import --file my_cache.json
```

- Importuje cache z pliku
- Przywraca odpowiedzi AI
- Gotowe do u≈ºycia w testach

### `clear` - Wyczy≈õƒá cache

```bash
python backend/scripts/manage_ai_cache.py clear
```

- Usuwa wszystkie zapisane odpowiedzi
- Resetuje cache do stanu poczƒÖtkowego

### `stats` - Poka≈º statystyki

```bash
python backend/scripts/manage_ai_cache.py stats
```

- Wy≈õwietla informacje o cache'u
- Rozmiar, liczba odpowiedzi, tryb testowy

## ‚öôÔ∏è Konfiguracja

### Zmienne ≈õrodowiskowe

```bash
# W≈ÇƒÖcz tryb testowy
TEST_MODE=true

# Plik cache'u
AI_CACHE_FILE=test_ai_responses_cache.json

# Plik eksportu
AI_EXPORT_FILE=test_ai_responses.json

# Zbieraj prawdziwe odpowiedzi
COLLECT_REAL_RESPONSES=true

# Maksymalny rozmiar cache'u
MAX_CACHE_SIZE=1000

# Czas ≈ºycia cache'u (sekundy)
CACHE_TTL=86400
```

### Pliki konfiguracyjne

- `backend/config/test_mode.py` - Konfiguracja trybu testowego
- `backend/middleware/cost_optimization.py` - Middleware cache'owania

## üîÑ Workflow testowy

### 1. Pierwszy raz - zbierz odpowiedzi

```bash
# W≈ÇƒÖcz tryb testowy
export TEST_MODE=true
export COLLECT_REAL_RESPONSES=true

# Zbierz odpowiedzi (kosztuje kredyty)
python backend/scripts/manage_ai_cache.py collect

# Eksportuj do pliku testowego
python backend/scripts/manage_ai_cache.py export --output test_responses.json
```

### 2. Testy - u≈ºywaj cache'u

```bash
# W≈ÇƒÖcz tryb testowy (bez zbierania)
export TEST_MODE=true
export COLLECT_REAL_RESPONSES=false

# Importuj zapisane odpowiedzi
python backend/scripts/manage_ai_cache.py import --file test_responses.json

# Uruchom testy (u≈ºywa cache'u, nie API)
python -m pytest backend/tests/
```

### 3. Aktualizacja cache'u

```bash
# Dodaj nowe odpowiedzi
python backend/scripts/manage_ai_cache.py collect

# Eksportuj zaktualizowany cache
python backend/scripts/manage_ai_cache.py export --output test_responses_v2.json
```

## üìä Monitorowanie

### Statystyki cache'u

```bash
python backend/scripts/manage_ai_cache.py stats
```

### Sprawd≈∫ pliki

```bash
# Cache lokalny
ls -la test_ai_responses_cache.json

# Eksportowany cache
ls -la test_ai_responses.json
```

## üõ†Ô∏è Integracja z testami

### W testach jednostkowych

```python
from backend.middleware.cost_optimization import test_cost_optimization_middleware

def test_analysis_with_cache():
    # Middleware automatycznie u≈ºyje cache'u w trybie testowym
    result = test_cost_optimization_middleware.process_request(
        prompt="Analyze this code",
        task_complexity=TaskComplexity.MEDIUM
    )
    assert result["cached"] == True
```

### W testach integracyjnych

```python
import os
os.environ["TEST_MODE"] = "true"

# Testy bƒôdƒÖ u≈ºywaƒá cache'u zamiast API
```

## üí° Wskaz√≥wki

### Optymalizacja koszt√≥w

- Zbierz odpowiedzi raz, u≈ºywaj wielokrotnie
- Eksportuj cache do repozytorium (bez kredyt√≥w)
- U≈ºywaj r√≥≈ºnych plik√≥w cache dla r√≥≈ºnych scenariuszy

### Debugowanie

- Sprawd≈∫ `stats` przed i po operacjach
- Sprawd≈∫ logi "Using cached AI response"
- Zweryfikuj pliki cache'u

### Bezpiecze≈Ñstwo

- Nie commituj plik√≥w cache z prawdziwymi danymi
- U≈ºywaj `.gitignore` dla plik√≥w cache
- Rotuj klucze API regularnie

## üö® Troubleshooting

### Cache nie dzia≈Ça

```bash
# Sprawd≈∫ tryb testowy
python backend/scripts/manage_ai_cache.py stats

# Sprawd≈∫ zmienne ≈õrodowiskowe
echo $TEST_MODE
```

### B≈Çƒôdy importu/eksportu

```bash
# Sprawd≈∫ uprawnienia plik√≥w
ls -la test_ai_responses*.json

# Sprawd≈∫ format JSON
python -m json.tool test_ai_responses.json
```

### Brak odpowiedzi w cache

```bash
# Sprawd≈∫ klucze cache
python -c "
from backend.middleware.cost_optimization import test_cost_optimization_middleware
print(test_cost_optimization_middleware.response_cache.cache.keys())
"
```
