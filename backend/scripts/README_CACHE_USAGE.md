# Jak u偶ywa Cache AI podczas analizy repozytori贸w

##  Przegld

System cache AI pozwala na:

- **Oszczdno koszt贸w** - unikaj ponownych wywoa API AI
- **Szybsze testy** - u偶ywaj zapisanych odpowiedzi
- **Przewidywalno** - identyczne wyniki dla tych samych repozytori贸w

##  Szybki start

### 1. Przygotuj cache AI

```bash
# Wcz tryb testowy
export TEST_MODE=true

# Zbierz odpowiedzi AI dla testowych repozytori贸w
python backend/scripts/manage_ai_cache.py collect

# Eksportuj cache do pliku
python backend/scripts/manage_ai_cache.py export --output production_cache.json
```

### 2. Uruchom backend z cache'em

```bash
# Ustaw zmienne rodowiskowe
export TEST_MODE=true
export AI_CACHE_FILE=production_cache.json

# Uruchom backend
python main.py
```

### 3. U偶yj frontendu normalnie

Frontend dziaa identycznie - cache jest niewidoczny dla u偶ytkownika.

##  Szczeg贸owe instrukcje

### Krok 1: Zbierz odpowiedzi AI

#### Opcja A: Automatyczne zbieranie

```bash
# Wcz tryb testowy i zbieranie
export TEST_MODE=true
export COLLECT_REAL_RESPONSES=true

# Uruchom analiz na testowych repozytoriach
python backend/scripts/manage_ai_cache.py collect
```

#### Opcja B: Rczne zbieranie przez frontend

1. Wcz tryb testowy: `export TEST_MODE=true`
2. Uruchom backend: `python main.py`
3. Otw贸rz frontend i przeanalizuj repozytoria
4. Odpowiedzi AI bd automatycznie zapisywane do cache'u

### Krok 2: Eksportuj cache

```bash
# Eksportuj do pliku produkcyjnego
python backend/scripts/manage_ai_cache.py export --output production_cache.json

# Sprawd藕 zawarto
python backend/scripts/manage_ai_cache.py stats
```

### Krok 3: U偶yj cache w produkcji

```bash
# Ustaw zmienne rodowiskowe
export TEST_MODE=true
export AI_CACHE_FILE=production_cache.json
export COLLECT_REAL_RESPONSES=false  # Nie zbieraj nowych odpowiedzi

# Uruchom backend
python main.py
```

### Krok 4: Testuj frontend

1. Otw贸rz frontend w przegldarce
2. Wklej URL repozytorium (np. `https://github.com/facebook/react`)
3. Kliknij "Analyze Repository"
4. **Cache bdzie u偶ywany automatycznie** - nie ma potrzeby zmian w frontendzie

##  Konfiguracja zaawansowana

### Zmienne rodowiskowe

```bash
# Wcz tryb testowy (wymagane)
TEST_MODE=true

# Plik cache'u (opcjonalne)
AI_CACHE_FILE=my_cache.json

# Czy zbiera nowe odpowiedzi (opcjonalne)
COLLECT_REAL_RESPONSES=false

# Maksymalny rozmiar cache'u (opcjonalne)
MAX_CACHE_SIZE=1000

# Czas 偶ycia cache'u w sekundach (opcjonalne)
CACHE_TTL=86400
```

### R贸偶ne scenariusze u偶ycia

#### Scenariusz 1: Development z cache'em

```bash
# Wcz cache, ale pozw贸l na nowe odpowiedzi
export TEST_MODE=true
export COLLECT_REAL_RESPONSES=true
python main.py
```

#### Scenariusz 2: Testy z cache'em

```bash
# U偶ywaj tylko cache'u, nie zbieraj nowych odpowiedzi
export TEST_MODE=true
export COLLECT_REAL_RESPONSES=false
python main.py
```

#### Scenariusz 3: Produkcja z cache'em

```bash
# U偶ywaj cache'u, ale nie zbieraj nowych odpowiedzi
export TEST_MODE=true
export AI_CACHE_FILE=production_cache.json
export COLLECT_REAL_RESPONSES=false
python main.py
```

##  Monitorowanie cache'u

### Sprawd藕 statystyki

```bash
python backend/scripts/manage_ai_cache.py stats
```

### Sprawd藕 zawarto cache'u

```bash
# Zobacz plik cache'u
cat test_ai_responses_cache.json | python -m json.tool
```

### Wyczy cache

```bash
python backend/scripts/manage_ai_cache.py clear
```

##  Workflow dla r贸偶nych przypadk贸w

### Dla developera

1. **Pierwszy raz:**

   ```bash
   export TEST_MODE=true
   export COLLECT_REAL_RESPONSES=true
   python main.py
   # Przeanalizuj kilka repozytori贸w przez frontend
   python backend/scripts/manage_ai_cache.py export --output dev_cache.json
   ```

2. **Codzienna praca:**
   ```bash
   export TEST_MODE=true
   export AI_CACHE_FILE=dev_cache.json
   export COLLECT_REAL_RESPONSES=false
   python main.py
   ```

### Dla testera

1. **Przygotuj cache:**

   ```bash
   export TEST_MODE=true
   export COLLECT_REAL_RESPONSES=true
   python main.py
   # Przeanalizuj testowe repozytoria
   python backend/scripts/manage_ai_cache.py export --output test_cache.json
   ```

2. **Uruchom testy:**
   ```bash
   export TEST_MODE=true
   export AI_CACHE_FILE=test_cache.json
   export COLLECT_REAL_RESPONSES=false
   python main.py
   # Uruchom testy - bd u偶ywa cache'u
   ```

### Dla produkcji

1. **Przygotuj cache produkcyjny:**

   ```bash
   export TEST_MODE=true
   export COLLECT_REAL_RESPONSES=true
   python main.py
   # Przeanalizuj popularne repozytoria
   python backend/scripts/manage_ai_cache.py export --output production_cache.json
   ```

2. **Wdr贸偶 z cache'em:**
   ```bash
   export TEST_MODE=true
   export AI_CACHE_FILE=production_cache.json
   export COLLECT_REAL_RESPONSES=false
   python main.py
   ```

##  Troubleshooting

### Cache nie dziaa

```bash
# Sprawd藕 tryb testowy
echo $TEST_MODE

# Sprawd藕 plik cache'u
ls -la test_ai_responses_cache.json

# Sprawd藕 logi backendu
# Powiniene zobaczy: "И Using test mode AI cache"
```

### Nowe odpowiedzi nie s zbierane

```bash
# Sprawd藕 zmienn
echo $COLLECT_REAL_RESPONSES

# Wcz zbieranie
export COLLECT_REAL_RESPONSES=true
```

### Bdy importu/eksportu

```bash
# Sprawd藕 uprawnienia plik贸w
ls -la *.json

# Sprawd藕 format JSON
python -m json.tool test_ai_responses_cache.json
```

##  Wskaz贸wki

### Optymalizacja koszt贸w

- Zbierz odpowiedzi raz, u偶ywaj wielokrotnie
- Eksportuj cache do repozytorium (bez kredyt贸w)
- U偶ywaj r贸偶nych plik贸w cache dla r贸偶nych rodowisk

### Debugowanie

- Sprawd藕 logi backendu: "Using cached AI response for prompt: ..."
- Sprawd藕 statystyki cache'u regularnie
- Zweryfikuj pliki cache'u

### Bezpieczestwo

- Nie commituj plik贸w cache z prawdziwymi danymi
- U偶ywaj `.gitignore` dla plik贸w cache
- Rotuj klucze API regularnie

##  Przykad kompletnego workflow

```bash
# 1. Przygotuj cache
export TEST_MODE=true
export COLLECT_REAL_RESPONSES=true
python main.py

# 2. Przeanalizuj repozytoria przez frontend
# (Otw贸rz http://localhost:3000 i przeanalizuj kilka repozytori贸w)

# 3. Eksportuj cache
python backend/scripts/manage_ai_cache.py export --output my_cache.json

# 4. U偶yj cache w testach
export TEST_MODE=true
export AI_CACHE_FILE=my_cache.json
export COLLECT_REAL_RESPONSES=false
python main.py

# 5. Testuj frontend - bdzie u偶ywa cache'u!
# (Otw贸rz http://localhost:3000 i przeanalizuj te same repozytoria)
```

**Cache AI jest teraz gotowy do u偶ycia w analizie repozytori贸w!** 
